{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pltпере\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('D:\\TITAN\\Kaggle\\Don`t overfit/train.csv')\n",
    "df_test = pd.read_csv('D:\\TITAN\\Kaggle\\Don`t overfit/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmnstodrop = ['id']\n",
    "X1= df_test.drop(colmnstodrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsToDrop = ['target', 'id']\n",
    "X=df_train.drop(ColumnsToDrop, axis=1)\n",
    "y=df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xnp = np.array(X)\n",
    "ynp = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['ID', 'DTC', 'RFC', 'ETC', 'SVC', 'ABC','n','p','k','ts']\n",
    "i=0\n",
    "df_cv_scores = pd.DataFrame(columns=cols)\n",
    "for ts in [0.1,0.05, 0.15]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xnp, ynp, test_size=ts)\n",
    "    for p in [2,3,5,10,100]:\n",
    "        for k in [2,3,4,5,6,7,8]:\n",
    "            for n in [2,3,4,5,6,7,8]:\n",
    "                \n",
    "                i+=1\n",
    "                #df_cv_scores.loc[i]\n",
    "                #print(i)\n",
    "                #print (n, p ,k, ts)\n",
    "                #n_dtc=7 p_dtc=2 k_dtc=8 ts_dtc=0.1\n",
    "                #n_rfc=7 p_rfc=100 k_rfc=8 ts_rfc=0.1\n",
    "                #n_etc=7 p__etc=100 k_etc=4 ts=0.1\n",
    "                #n_svc=2 p_svc=2 k_svc=7 ts_svc=0.1\n",
    "                #n_abc=2 p_abc=100 k_abc=6 ts_abc=0.1\n",
    "                clf1 = DecisionTreeClassifier(max_depth=None, min_samples_split=n, random_state=0)\n",
    "                scores1 = cross_val_score(clf1, X, y, cv=k)\n",
    "                #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "            \n",
    "                clf2 = RandomForestClassifier (n_estimators=p, max_depth=None,min_samples_split=n, random_state=0)\n",
    "                scores2 = cross_val_score(clf2, X, y, cv=k)\n",
    "                #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))                   \n",
    "\n",
    "                clf3 = ExtraTreesClassifier(n_estimators=p, max_depth=None, min_samples_split=n, random_state=0)\n",
    "                scores3 = cross_val_score(clf3, X, y, cv=k)\n",
    "                #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))\n",
    "           \n",
    "            \n",
    "                clf4 = svm.SVC(gamma='scale')\n",
    "                scores4 = cross_val_score(clf4, X, y, cv=k)\n",
    "                #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std() * 2))\n",
    "            \n",
    "                clf5 = AdaBoostClassifier(n_estimators=p)\n",
    "                scores5 = cross_val_score(clf5, X,y, cv=k)\n",
    "                #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores5.mean(), scores8.std() * 2))\n",
    "                \n",
    "                df_cv_scores.loc[i,'ID'] = i\n",
    "                df_cv_scores.loc[i,'DTC'] = scores1.mean()\n",
    "                df_cv_scores.loc[i,'RFC'] = scores2.mean()\n",
    "                df_cv_scores.loc[i,'ETC'] = scores3.mean()\n",
    "                df_cv_scores.loc[i,'SVC'] = scores4.mean()\n",
    "                df_cv_scores.loc[i,'ABC'] = scores5.mean()\n",
    "               # (n, p ,k, ts)\n",
    "                df_cv_scores.loc[i,'n'] = n\n",
    "                df_cv_scores.loc[i,'p'] = p\n",
    "                df_cv_scores.loc[i,'k'] = k\n",
    "                df_cv_scores.loc[i,'ts']= ts\n",
    "                \n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "df_cv_scores.head(5)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_dtc=7 p_dtc=2 k_dtc=8 ts_dtc=0.1\n",
    "#n_rfc=7 p_rfc=100 k_rfc=8 ts_rfc=0.1\n",
    "#n_etc=7 p__etc=100 k_etc=4 ts=0.1\n",
    "#n_svc=2 p_svc=2 k_svc=7 ts_svc=0.1\n",
    "#n_abc=2 p_abc=100 k_abc=6 ts_abc=0.1\n",
    "clf1 = DecisionTreeClassifier(max_depth=None, min_samples_split=7, random_state=0)\n",
    "scores1 = cross_val_score(clf1, X, y, cv=8)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "            \n",
    "clf2 = RandomForestClassifier (n_estimators=100, max_depth=None,min_samples_split=7, random_state=0)\n",
    "scores2 = cross_val_score(clf2, X, y, cv=8)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))                   \n",
    "\n",
    "clf3 = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=7, random_state=0)\n",
    "scores3 = cross_val_score(clf3, X, y, cv=4)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))\n",
    "           \n",
    "            \n",
    "clf4 = svm.SVC(gamma='scale')\n",
    "scores4 = cross_val_score(clf4, X, y, cv=7)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std() * 2))\n",
    "            \n",
    "clf5 = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=250, random_state=None)\n",
    "scores5 = cross_val_score(clf5, X,y, cv=6)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores5.mean(), scores8.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=150, random_state=None)\n",
    "scores5 = cross_val_score(clf5, X,y, cv=6)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores5.mean(), scores5.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEnsemble:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "    def predict (self, X):\n",
    "        preds = [model. predict(X) for model in self.models]\n",
    "        res = []\n",
    "        for i in range(len(X)):\n",
    "            line = [preds[j][i] for j in range (len(preds))]\n",
    "            res.append(round(sum(line) / len(line)))\n",
    "        return res\n",
    "model = myEnsemble([clf5])\n",
    "model.fit(X, y)\n",
    "r = model.predict(X1)\n",
    "#print(sum(r == y_test) / len(r == y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': df_test.id, 'target': r})\n",
    "#submission = pd.DataFrame({\"Id\": ID,\"SalePrice\": an})\n",
    "my_submission.to_csv(\"don`t oberfit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnp, ynp, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', \n",
    "     RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "   {\n",
    "    \"clf\": [RandomForestClassifier(), ExtraTreesClassifier()],\n",
    "    \"clf__n_estimators\": [50, 100,150,200, 250, 500],\n",
    "    \"clf__max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"clf__min_samples_split\": [2, 3, 5]\n",
    "   },\n",
    "   {\n",
    "    \"clf\": [AdaBoostClassifier()],\n",
    "    \"clf__n_estimators\": [100,150, 200, 175, 225, 250, 500],\n",
    "   }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5, \n",
    "                    n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "res = (\n",
    "    pd.DataFrame({\n",
    "        \"mean_test_score\": grid.cv_results_[\"mean_test_score\"],\n",
    "        \"mean_fit_time\": grid.cv_results_[\"mean_fit_time\"]})\n",
    "      .join(pd.io.json.json_normalize(grid.cv_results_[\"params\"]).add_prefix(\"param_\"))\n",
    ")\n",
    "print(f\"best score: {grid.best_score_}\")\n",
    "print(f\"best params: {grid.best_params_}\")\n",
    "print(\"*\" * 80)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = datab['true']\n",
    "for algorythm in datab.columns[1:]:\n",
    "    yscores = datab[algorythm]\n",
    "    precision, recall, thresholds = me.precision_recall_curve(ytrue, yscores)\n",
    "    plt.plot(recall, precision, label = algorythm)\n",
    "    plt.xlim(0.0,1)\n",
    "    plt.ylim(0.5, 1)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
