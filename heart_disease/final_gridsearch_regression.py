"""
final_gridsearch_regressions.py
Ğ¢Ñ€ĞµÑ‚Ğ¸Ğ¹ (Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹) GridSearchCV â€” ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ• Ğ›Ğ£Ğ§Ğ¨Ğ˜Ğ• ĞŸĞĞ ĞĞœĞ•Ğ¢Ğ Ğ« (Ğ½Ğ° Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ 2026-02-25)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LogisticRegression:                                            â”‚
â”‚    â€¢ C: 2                                                       â”‚
â”‚    â€¢ penalty: l2                                                â”‚
â”‚    â€¢ solver: liblinear                                          â”‚
â”‚    â€¢ class_weight: balanced                                     â”‚
â”‚    â€¢ max_iter: 500                                              â”‚
â”‚    â€¢ F1: 0.8679                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LinearSVC:                                                     â”‚
â”‚    â€¢ C: 1                                                       â”‚
â”‚    â€¢ penalty: l1                                                â”‚
â”‚    â€¢ class_weight: balanced                                     â”‚
â”‚    â€¢ max_iter: 500-1000                                         â”‚
â”‚    â€¢ F1: 0.8664                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import pandas as pd
import numpy as np
import time
import json
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print(" Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ GRIDSEARCHCV â€” Ğ£Ğ¢ĞĞ§ĞĞ•ĞĞ˜Ğ• ĞŸĞĞ ĞĞœĞ•Ğ¢Ğ ĞĞ’")
print("=" * 80)
print(f"ğŸ• ĞĞ°Ñ‡Ğ°Ğ»Ğ¾: {time.strftime('%H:%M:%S')}")

total_start = time.time()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv('train_fixed.csv')
X = df.drop('Heart Disease', axis=1)
y = df['Heart Disease'].map({'Absence': 0, 'Presence': 1})

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=10000, random_state=42, stratify=y
)

print(f"\nâœ… Train: {len(X_train):,} | Test: {len(X_test):,}")
print("=" * 80)

# Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ (Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ½Ğ° Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚)
baseline = {
    'LogisticRegression': 0.8679,
    'LinearSVC': 0.8664
}

all_results = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞœĞĞ”Ğ•Ğ›Ğ¬ 1: LogisticRegression + GridSearchCV (ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n" + "=" * 80)
print("1ï¸âƒ£ LogisticRegression + GridSearchCV (ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ)")
print("=" * 80)
start = time.time()

param_grid_lr = {
    'C': [1.8, 1.9, 2.1, 2.2],
    'penalty': ['l2'],
    'solver': ['liblinear'],
    'class_weight': ['balanced'],
    'max_iter': [400, 450, 550, 600]
}

total_combinations = (len(param_grid_lr['C']) * 
                      len(param_grid_lr['penalty']) * 
                      len(param_grid_lr['solver']) * 
                      len(param_grid_lr['class_weight']) * 
                      len(param_grid_lr['max_iter']))

print(f"ğŸ“Š ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹: {total_combinations} Ã— 5 Ñ„Ğ¾Ğ»Ğ´Ğ¾Ğ² = {total_combinations * 5} Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¹")

grid_lr = GridSearchCV(
    LogisticRegression(random_state=42, n_jobs=-1),
    param_grid_lr, 
    cv=5, 
    scoring='f1', 
    n_jobs=-1, 
    verbose=1
)
grid_lr.fit(X_train, y_train)

elapsed = time.time() - start
y_pred = grid_lr.predict(X_test)
y_proba = grid_lr.predict_proba(X_test)[:, 1]

test_f1 = f1_score(y_test, y_pred)
test_acc = accuracy_score(y_test, y_pred)
test_auc = roc_auc_score(y_test, y_proba)

results_lr = {
    'model': 'LogisticRegression_FinalGridSearch',
    'time_min': elapsed / 60,
    'best_params': grid_lr.best_params_,
    'cv_best_score': float(grid_lr.best_score_),
    'test_accuracy': float(test_acc),
    'test_f1': float(test_f1),
    'test_roc_auc': float(test_auc),
    'baseline_f1': baseline['LogisticRegression'],
    'improvement': float(test_f1 - baseline['LogisticRegression'])
}

# ğŸ”¥ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑ€Ğ°Ğ·Ñƒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
with open('results_lr_final_grid.json', 'w', encoding='utf-8') as f:
    json.dump(results_lr, f, indent=2)

all_results.append(results_lr)

print(f"\nâ±ï¸ {elapsed/60:.2f} Ğ¼Ğ¸Ğ½ | F1: {test_f1:.4f}")
print(f"ğŸ“‹ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {grid_lr.best_params_}")
print(f"ğŸ“ˆ Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ: {test_f1 - baseline['LogisticRegression']:+.4f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞœĞĞ”Ğ•Ğ›Ğ¬ 2: LinearSVC + GridSearchCV (ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n" + "=" * 80)
print("2ï¸âƒ£ LinearSVC + GridSearchCV (ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ)")
print("=" * 80)
start = time.time()

param_grid_svc = {
    'C': [0.8, 0.9, 1.1, 1.2],
    'penalty': ['l1'],
    'class_weight': ['balanced'],
    'max_iter': [600, 700, 800, 900]
}

total_combinations = (len(param_grid_svc['C']) * 
                      len(param_grid_svc['penalty']) * 
                      len(param_grid_svc['class_weight']) * 
                      len(param_grid_svc['max_iter']))

print(f"ğŸ“Š ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹: {total_combinations} Ã— 5 Ñ„Ğ¾Ğ»Ğ´Ğ¾Ğ² = {total_combinations * 5} Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¹")

grid_svc = GridSearchCV(
    LinearSVC(random_state=42),
    param_grid_svc, 
    cv=5, 
    scoring='f1', 
    n_jobs=-1, 
    verbose=1
)
grid_svc.fit(X_train, y_train)

elapsed = time.time() - start
y_pred = grid_svc.predict(X_test)

test_f1 = f1_score(y_test, y_pred)
test_acc = accuracy_score(y_test, y_pred)

results_svc = {
    'model': 'LinearSVC_FinalGridSearch',
    'time_min': elapsed / 60,
    'best_params': grid_svc.best_params_,
    'cv_best_score': float(grid_svc.best_score_),
    'test_accuracy': float(test_acc),
    'test_f1': float(test_f1),
    'test_roc_auc': 0,
    'baseline_f1': baseline['LinearSVC'],
    'improvement': float(test_f1 - baseline['LinearSVC'])
}

# ğŸ”¥ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑ€Ğ°Ğ·Ñƒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
with open('results_linearsvc_final_grid.json', 'w', encoding='utf-8') as f:
    json.dump(results_svc, f, indent=2)

all_results.append(results_svc)

print(f"\nâ±ï¸ {elapsed/60:.2f} Ğ¼Ğ¸Ğ½ | F1: {test_f1:.4f}")
print(f"ğŸ“‹ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {grid_svc.best_params_}")
print(f"ğŸ“ˆ Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ: {test_f1 - baseline['LinearSVC']:+.4f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ ĞĞ¢Ğ§ĞĞ¢
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
total_elapsed = time.time() - total_start

print("\n" + "=" * 80)
print("ğŸ“Š Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ ĞĞ¢Ğ§ĞĞ¢")
print("=" * 80)

print(f"\n{'ĞœĞ¾Ğ´ĞµĞ»ÑŒ':<35} {'Ğ‘Ğ°Ğ·Ğ°':<8} {'Ğ¤Ğ¸Ğ½Ğ°Ğ»':<8} {'Î”':<10} {'Ğ’Ñ€ĞµĞ¼Ñ':<10}")
print("-" * 80)
for res in sorted(all_results, key=lambda x: x['test_f1'], reverse=True):
    name = res['model'].replace('_FinalGridSearch', '')
    print(f"{name:<35} {res['baseline_f1']:<8.4f} {res['test_f1']:<8.4f} {res['improvement']:+.4f} {res['time_min']:<10.2f} Ğ¼Ğ¸Ğ½")

print(f"\nâ±ï¸ ĞĞ‘Ğ©Ğ•Ğ• Ğ’Ğ Ğ•ĞœĞ¯: {total_elapsed/60:.2f} Ğ¼Ğ¸Ğ½ÑƒÑ‚")

# Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
best = max(all_results, key=lambda x: x['test_f1'])
print(f"\nğŸ† Ğ›Ğ£Ğ§Ğ¨ĞĞ¯ ĞœĞĞ”Ğ•Ğ›Ğ¬: {best['model']}")
print(f"   F1-Score:  {best['test_f1']:.4f}")
print(f"   Accuracy:  {best['test_accuracy']:.4f}")
print(f"   Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ: {best['improvement']:+.4f}")
print(f"   ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {best['best_params']}")

# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
with open('results_regressions_final_summary.json', 'w', encoding='utf-8') as f:
    json.dump({
        'total_time_min': total_elapsed / 60,
        'all_results': all_results,
        'best_model': best
    }, f, indent=2)

print("\nâœ… Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹:")
print("   â€¢ results_lr_final_grid.json")
print("   â€¢ results_linearsvc_final_grid.json")
print("   â€¢ results_regressions_final_summary.json")
print(f"\nğŸ• ĞšĞ¾Ğ½ĞµÑ†: {time.strftime('%H:%M:%S')}")
print("=" * 80)