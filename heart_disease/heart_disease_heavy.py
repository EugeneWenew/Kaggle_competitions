"""
heart_disease_heavy_local.py
Ğ¢ÑĞ¶Ñ‘Ğ»Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â€” Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ±ĞµĞ· GridSearchCV
"""

import pandas as pd
import numpy as np
import time
import json
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.utils import resample
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("ğŸ‹ï¸ Ğ¢Ğ¯Ğ–ĞĞ›Ğ«Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜ â€” Ğ‘Ğ«Ğ¡Ğ¢Ğ ĞĞ¯ ĞĞ¦Ğ•ĞĞšĞ")
print("=" * 70)
print(f"ğŸ• ĞĞ°Ñ‡Ğ°Ğ»Ğ¾: {time.strftime('%H:%M:%S')}")

total_start = time.time()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv('train_fixed.csv')
X = df.drop('Heart Disease', axis=1)
y = df['Heart Disease'].map({'Absence': 0, 'Presence': 1})

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=10000, random_state=42, stratify=y
)

print(f"\nâœ… Train: {len(X_train):,} | Test: {len(X_test):,}")
print("=" * 70)

all_results = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞœĞĞ”Ğ•Ğ›Ğ¬ 1: XGBoost
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n1ï¸âƒ£ XGBoost...")
try:
    from xgboost import XGBClassifier
    start = time.time()
    
    model = XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        n_jobs=-1,
        random_state=42,
        verbosity=0
    )
    model.fit(X_train, y_train)
    
    elapsed = time.time() - start
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    results = {
        'model': 'XGBoost',
        'time_min': elapsed / 60,
        'test_accuracy': float(accuracy_score(y_test, y_pred)),
        'test_f1': float(f1_score(y_test, y_pred)),
        'test_roc_auc': float(roc_auc_score(y_test, y_proba))
    }
    all_results.append(results)
    
    with open('results_xgboost_local.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2)
    
    print(f"   â±ï¸ {elapsed/60:.2f} Ğ¼Ğ¸Ğ½ | F1: {results['test_f1']:.4f} | Acc: {results['test_accuracy']:.4f}")
    
except ImportError:
    print("   âš ï¸ XGBoost Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ (pip install xgboost)")
    all_results.append({'model': 'XGBoost', 'time_min': 0, 'test_f1': 0, 'test_accuracy': 0, 'test_roc_auc': 0})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞœĞĞ”Ğ•Ğ›Ğ¬ 2: LightGBM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n2ï¸âƒ£ LightGBM...")
try:
    from lightgbm import LGBMClassifier
    start = time.time()
    
    model = LGBMClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        n_jobs=-1,
        random_state=42,
        verbose=-1
    )
    model.fit(X_train, y_train)
    
    elapsed = time.time() - start
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    results = {
        'model': 'LightGBM',
        'time_min': elapsed / 60,
        'test_accuracy': float(accuracy_score(y_test, y_pred)),
        'test_f1': float(f1_score(y_test, y_pred)),
        'test_roc_auc': float(roc_auc_score(y_test, y_proba))
    }
    all_results.append(results)
    
    with open('results_lightgbm_local.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2)
    
    print(f"   â±ï¸ {elapsed/60:.2f} Ğ¼Ğ¸Ğ½ | F1: {results['test_f1']:.4f} | Acc: {results['test_accuracy']:.4f}")
    
except ImportError:
    print("   âš ï¸ LightGBM Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ (pip install lightgbm)")
    all_results.append({'model': 'LightGBM', 'time_min': 0, 'test_f1': 0, 'test_accuracy': 0, 'test_roc_auc': 0})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞœĞĞ”Ğ•Ğ›Ğ¬ 3: SVC RBF (Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ 50k)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n3ï¸âƒ£ SVC RBF (Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ 50k)...")
start = time.time()

# Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
X_train_sub, y_train_sub = resample(X_train, y_train, n_samples=50000, random_state=42)

model = SVC(kernel='rbf', C=10, gamma=0.01, probability=True, random_state=42)
model.fit(X_train_sub, y_train_sub)

elapsed = time.time() - start
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

results = {
    'model': 'SVC_RBF_50k',
    'time_min': elapsed / 60,
    'test_accuracy': float(accuracy_score(y_test, y_pred)),
    'test_f1': float(f1_score(y_test, y_pred)),
    'test_roc_auc': float(roc_auc_score(y_test, y_proba))
}
all_results.append(results)

with open('results_svc_rbf_local.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)

print(f"   â±ï¸ {elapsed/60:.2f} Ğ¼Ğ¸Ğ½ | F1: {results['test_f1']:.4f} | Acc: {results['test_accuracy']:.4f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ ĞĞ¢Ğ§ĞĞ¢
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
total_elapsed = time.time() - total_start

print("\n" + "=" * 70)
print("ğŸ“Š Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ ĞĞ¢Ğ§ĞĞ¢")
print("=" * 70)

print(f"\n{'ĞœĞ¾Ğ´ĞµĞ»ÑŒ':<25} {'F1':<10} {'Accuracy':<10} {'Ğ’Ñ€ĞµĞ¼Ñ':<10}")
print("-" * 70)
for res in sorted(all_results, key=lambda x: x['test_f1'], reverse=True):
    print(f"{res['model']:<25} {res['test_f1']:<10.4f} {res['test_accuracy']:<10.4f} {res['time_min']:<10.2f} Ğ¼Ğ¸Ğ½")

print(f"\nâ±ï¸ ĞĞ‘Ğ©Ğ•Ğ• Ğ’Ğ Ğ•ĞœĞ¯: {total_elapsed/60:.2f} Ğ¼Ğ¸Ğ½ÑƒÑ‚")

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ¹
print("\n" + "=" * 70)
print("ğŸ“ˆ Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• Ğ¡ Ğ‘ĞĞ—ĞĞ’Ğ«ĞœĞ˜ ĞœĞĞ”Ğ•Ğ›Ğ¯ĞœĞ˜")
print("=" * 70)

baseline = {
    'VotingEnsemble': 0.8693,
    'RandomForest': 0.8659,
    'LogisticRegression': 0.8656,
    'LinearSVC': 0.8648
}

print(f"\n{'ĞœĞ¾Ğ´ĞµĞ»ÑŒ':<25} {'Ğ‘Ğ°Ğ·Ğ°':<10} {'Heavy':<10} {'Ğ Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ°':<10}")
print("-" * 70)
for res in sorted(all_results, key=lambda x: x['test_f1'], reverse=True):
    name = res['model'].replace('_50k', '').replace('_RBF', '')
    base_f1 = baseline.get('RandomForest', 0.87)  # Ğ”Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
    diff = res['test_f1'] - base_f1
    print(f"{name:<25} {base_f1:<10.4f} {res['test_f1']:<10.4f} {diff:+.4f}")

print("\nâœ… Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: results_*_local.json")
print(f"\nğŸ• ĞšĞ¾Ğ½ĞµÑ†: {time.strftime('%H:%M:%S')}")
print("=" * 70)